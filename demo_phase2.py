#!/usr/bin/env python3
"""
Phase 2 Demo Script for jtext System

This script demonstrates the new Phase 2 features including:
- Enhanced LLM integration with Ollama
- Document processing (PDF, DOCX, PPTX, HTML)
- Audio transcription with Whisper
- Context-aware correction
"""

import os
import sys
import time
from pathlib import Path
import tempfile
import json

# Add the project root to the Python path
sys.path.insert(0, str(Path(__file__).parent))

from jtext.core.ocr_hybrid import HybridOCR, ProcessingResult
from jtext.processing.document_extractor import DocumentExtractor
from jtext.transcription.audio_transcriber import AudioTranscriber
from jtext.correction.context_aware_corrector import ContextAwareCorrector
from jtext.utils.logging import setup_logging
from jtext.utils.io_utils import ensure_output_dir, save_results


def create_sample_documents():
    """Create sample documents for testing."""
    print("ğŸ“„ Creating sample documents...")

    # Create a sample text file
    sample_text = """
    ã‚·ã‚¹ãƒ†ãƒ è¦æ±‚å®šç¾©æ›¸
    
    1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
    ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚
    
    2. æ©Ÿèƒ½è¦ä»¶
    - OCRæ©Ÿèƒ½: ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
    - ASRæ©Ÿèƒ½: éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å¤‰æ›
    - LLMä¿®æ­£: æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ç²¾åº¦å‘ä¸Š
    
    3. éæ©Ÿèƒ½è¦ä»¶
    - å‡¦ç†é€Ÿåº¦: 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Š5ç§’ä»¥å†…
    - ç²¾åº¦: 95%ä»¥ä¸Š
    - å¯¾å¿œè¨€èª: æ—¥æœ¬èªã€è‹±èª
    """

    # Create sample HTML
    sample_html = """
    <html>
    <head><title>æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ </title></head>
    <body>
        <h1>ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦</h1>
        <p>ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®é«˜ç²¾åº¦å‡¦ç†ã‚’æä¾›ã—ã¾ã™ã€‚</p>
        <ul>
            <li>OCRæ©Ÿèƒ½</li>
            <li>ASRæ©Ÿèƒ½</li>
            <li>LLMä¿®æ­£</li>
        </ul>
        <img src="sample.jpg" alt="ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ">
        <a href="https://example.com">è©³ç´°æƒ…å ±</a>
    </body>
    </html>
    """

    # Create temporary files
    temp_dir = Path(tempfile.mkdtemp())

    # Text file
    text_file = temp_dir / "sample.txt"
    with open(text_file, "w", encoding="utf-8") as f:
        f.write(sample_text)

    # HTML file
    html_file = temp_dir / "sample.html"
    with open(html_file, "w", encoding="utf-8") as f:
        f.write(sample_html)

    print(f"âœ… Created sample documents in: {temp_dir}")
    return temp_dir, [text_file, html_file]


def demo_enhanced_ocr():
    """Demonstrate enhanced OCR with LLM correction."""
    print("\nğŸ” Enhanced OCR with LLM Correction Demo")
    print("=" * 50)

    # Initialize OCR processor with LLM correction
    ocr_processor = HybridOCR(enable_correction=True, llm_model="llama2")

    # Check if we have a sample image
    sample_image = Path("sample_image.png")
    if not sample_image.exists():
        print("âš ï¸  No sample image found. Please add a sample_image.png file.")
        return

    try:
        print(f"Processing image: {sample_image}")
        result = ocr_processor.process_image(str(sample_image))

        print(f"âœ… OCR completed in {result.processing_time:.2f}s")
        print(f"ğŸ“Š Confidence: {result.confidence:.2f}")
        print(f"ğŸ”§ Corrections applied: {result.corrections_applied}")
        print(f"ğŸ“ Text length: {len(result.text)} characters")

        # Save results
        output_dir = Path("demo_output")
        ensure_output_dir(output_dir)
        save_results(result, output_dir / "enhanced_ocr")

        print(f"ğŸ’¾ Results saved to: {output_dir}")

    except Exception as e:
        print(f"âŒ OCR processing failed: {e}")


def demo_document_processing():
    """Demonstrate document processing capabilities."""
    print("\nğŸ“„ Document Processing Demo")
    print("=" * 50)

    # Create sample documents
    temp_dir, sample_files = create_sample_documents()

    # Initialize document extractor
    extractor = DocumentExtractor()

    for file_path in sample_files:
        try:
            print(f"Processing: {file_path.name}")
            result = extractor.extract_text(str(file_path))

            print(f"âœ… Extraction completed in {result.processing_time:.2f}s")
            print(f"ğŸ“ Text length: {len(result.text)} characters")

            # Show document metadata
            if hasattr(result, "document_metadata"):
                metadata = result.document_metadata
                print(f"ğŸ“Š Document format: {metadata.get('format', 'unknown')}")
                if "pages" in metadata:
                    print(f"ğŸ“„ Pages: {metadata['pages']}")
                if "paragraphs" in metadata:
                    print(f"ğŸ“ Paragraphs: {metadata['paragraphs']}")

            # Save results
            output_dir = Path("demo_output")
            ensure_output_dir(output_dir)
            save_results(result, output_dir / file_path.stem)

        except Exception as e:
            print(f"âŒ Document processing failed: {e}")

    # Cleanup
    import shutil

    shutil.rmtree(temp_dir)


def demo_audio_transcription():
    """Demonstrate audio transcription capabilities."""
    print("\nğŸ¤ Audio Transcription Demo")
    print("=" * 50)

    # Initialize audio transcriber
    transcriber = AudioTranscriber(model_size="base")

    # Check for sample audio files
    audio_extensions = [".mp3", ".wav", ".m4a", ".mp4"]
    sample_audio = None

    for ext in audio_extensions:
        audio_file = Path(f"sample_audio{ext}")
        if audio_file.exists():
            sample_audio = audio_file
            break

    if not sample_audio:
        print("âš ï¸  No sample audio files found. Please add a sample audio file.")
        print("Supported formats: .mp3, .wav, .m4a, .mp4")
        return

    try:
        print(f"Processing audio: {sample_audio}")
        result = transcriber.transcribe_audio(str(sample_audio), language="ja")

        print(f"âœ… Transcription completed in {result.processing_time:.2f}s")
        print(f"ğŸ“Š Confidence: {result.confidence:.2f}")
        print(f"ğŸ“ Text length: {len(result.text)} characters")

        # Show audio metadata
        if hasattr(result, "audio_metadata"):
            metadata = result.audio_metadata
            print(f"ğŸŒ Language: {metadata.get('language', 'unknown')}")
            print(f"â±ï¸  Duration: {metadata.get('duration', 0):.2f}s")
            print(f"ğŸ¤– Model: {metadata.get('model_size', 'unknown')}")

        # Save results
        output_dir = Path("demo_output")
        ensure_output_dir(output_dir)
        save_results(result, output_dir / "audio_transcription")

        print(f"ğŸ’¾ Results saved to: {output_dir}")

    except Exception as e:
        print(f"âŒ Audio transcription failed: {e}")


def demo_context_aware_correction():
    """Demonstrate context-aware correction."""
    print("\nğŸ§  Context-Aware Correction Demo")
    print("=" * 50)

    # Initialize context-aware corrector
    corrector = ContextAwareCorrector(model="llama2")

    # Sample OCR text with errors
    sample_ocr_text = """
    ã‚·ã‚¹ãƒ†ãƒ è¦æ±‚å®šç¾©æ›¸
    
    1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
    ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚
    
    2. æ©Ÿèƒ½è¦ä»¶
    - OCRæ©Ÿèƒ½: ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
    - ASRæ©Ÿèƒ½: éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å¤‰æ›
    - LLMä¿®æ­£: æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ç²¾åº¦å‘ä¸Š
    
    3. éæ©Ÿèƒ½è¦ä»¶
    - å‡¦ç†é€Ÿåº¦: 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Š5ç§’ä»¥å†…
    - ç²¾åº¦: 95%ä»¥ä¸Š
    - å¯¾å¿œè¨€èª: æ—¥æœ¬èªã€è‹±èª
    """

    # Document metadata for context
    document_metadata = {
        "format": "pdf",
        "pages": 3,
        "has_tables": True,
        "has_images": False,
        "language": "ja",
    }

    try:
        print("Applying context-aware correction...")
        corrected_text, corrections = corrector.correct_with_context(
            text=sample_ocr_text,
            context_type="technical",
            document_metadata=document_metadata,
        )

        print(f"âœ… Correction completed")
        print(f"ğŸ”§ Corrections applied: {corrections}")
        print(f"ğŸ“ Original length: {len(sample_ocr_text)} characters")
        print(f"ğŸ“ Corrected length: {len(corrected_text)} characters")

        # Save results
        output_dir = Path("demo_output")
        ensure_output_dir(output_dir)

        # Save original and corrected text
        with open(
            output_dir / "context_aware_original.txt", "w", encoding="utf-8"
        ) as f:
            f.write(sample_ocr_text)

        with open(
            output_dir / "context_aware_corrected.txt", "w", encoding="utf-8"
        ) as f:
            f.write(corrected_text)

        print(f"ğŸ’¾ Results saved to: {output_dir}")

    except Exception as e:
        print(f"âŒ Context-aware correction failed: {e}")


def demo_ollama_integration():
    """Demonstrate Ollama integration status."""
    print("\nğŸ¤– Ollama Integration Status")
    print("=" * 50)

    try:
        import requests

        # Check if Ollama is running
        response = requests.get("http://localhost:11434/api/tags", timeout=5)

        if response.status_code == 200:
            models = response.json().get("models", [])
            available_models = [model["name"] for model in models]

            print("âœ… Ollama is running")
            print(f"ğŸ“¦ Available models: {available_models}")

            # Check for recommended models
            recommended_models = ["llama2", "codellama", "mistral"]
            installed_recommended = [
                model for model in recommended_models if model in available_models
            ]

            if installed_recommended:
                print(f"ğŸ¯ Recommended models installed: {installed_recommended}")
            else:
                print("âš ï¸  No recommended models found. Consider installing:")
                print("   - llama2: General purpose model")
                print("   - codellama: Code-focused model")
                print("   - mistral: Efficient model")
        else:
            print("âŒ Ollama API not responding")

    except requests.exceptions.RequestException:
        print("âŒ Ollama is not running")
        print("ğŸ’¡ To start Ollama:")
        print("   1. Install Ollama: https://ollama.ai/")
        print("   2. Start Ollama: ollama serve")
        print("   3. Pull a model: ollama pull llama2")
    except ImportError:
        print("âŒ Requests library not available")


def main():
    """Main demo function."""
    print("ğŸš€ jtext Phase 2 Features Demo")
    print("=" * 60)
    print("This demo showcases the new Phase 2 features:")
    print("- Enhanced LLM integration with Ollama")
    print("- Document processing (PDF, DOCX, PPTX, HTML)")
    print("- Audio transcription with Whisper")
    print("- Context-aware correction")
    print("=" * 60)

    # Setup logging
    setup_logging(verbose=True)

    # Run demos
    demo_ollama_integration()
    demo_enhanced_ocr()
    demo_document_processing()
    demo_audio_transcription()
    demo_context_aware_correction()

    print("\nğŸ‰ Phase 2 Demo Complete!")
    print("=" * 60)
    print("ğŸ“ Check the 'demo_output' directory for results")
    print("ğŸ”§ All Phase 2 features are now available in the jtext CLI")
    print("ğŸ’¡ Use 'jtext --help' to see all available commands")


if __name__ == "__main__":
    main()
